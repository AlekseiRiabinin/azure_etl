{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3b3bd6e-f248-4226-96d4-2b8872cde657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DAG: mock_spark_minio_etl>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from airflow.models import DAG\n",
    "from airflow.operators.python import PythonOperator\n",
    "import graphviz\n",
    "from IPython.display import display, Markdown, HTML\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ipywidgets import interact, FloatSlider\n",
    "\n",
    "# Configure visualization settings\n",
    "plt.style.use('seaborn')\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 5)\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "# Enhanced mock function with interactive elements\n",
    "def mock_spark_minio_etl(**kwargs):\n",
    "    \"\"\"Mock Spark/MinIO ETL with visual feedback\"\"\"\n",
    "    display(Markdown(\"## üöÄ Spark/MinIO ETL Simulation\"))\n",
    "    \n",
    "    # Simulate data processing\n",
    "    with plt.ioff():\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "        \n",
    "        # Mock data distribution\n",
    "        data = pd.DataFrame({\n",
    "            'value': np.random.normal(100, 15, 10000),\n",
    "            'timestamp': pd.date_range(end=datetime.now(), periods=10000, freq='T')\n",
    "        })\n",
    "        sns.histplot(data['value'], bins=30, ax=ax1, kde=True)\n",
    "        ax1.set_title(\"üìä Smart Meter Value Distribution\")\n",
    "        \n",
    "        # Mock throughput timeline\n",
    "        throughput = np.cumsum(np.random.poisson(500, 24))\n",
    "        sns.lineplot(x=range(24), y=throughput, ax=ax2, marker='o')\n",
    "        ax2.set_title(\"‚è± Records Processed by Hour\")\n",
    "        ax2.set_xlabel(\"Hour of Day\")\n",
    "        ax2.set_ylabel(\"Total Records\")\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    # Interactive parameter control\n",
    "    display(Markdown(\"### üéö Processing Parameters\"))\n",
    "    def show_effect(processing_time=2.0, error_rate=0.05):\n",
    "        display(Markdown(f\"\"\"\n",
    "        - **Simulated Processing Time**: {processing_time:.1f}s per 1000 records\n",
    "        - **Simulated Error Rate**: {error_rate:.1%}\n",
    "        \"\"\"))\n",
    "    \n",
    "    interact(show_effect, \n",
    "             processing_time=FloatSlider(1.0, 0.5, 5.0, 0.5),\n",
    "             error_rate=FloatSlider(0.05, 0.0, 0.2, 0.01))\n",
    "    \n",
    "    return {\n",
    "        \"status\": \"success\",\n",
    "        \"records_processed\": 10000,\n",
    "        \"output_path\": \"s3a://default/output/processed_data.parquet\"\n",
    "    }\n",
    "\n",
    "# Create DAG with enhanced metadata\n",
    "with DAG(\n",
    "    dag_id=\"spark_minio_etl\",\n",
    "    schedule=\"@hourly\",\n",
    "    start_date=datetime(2024, 1, 1),\n",
    "    catchup=False,\n",
    "    default_args={\n",
    "        \"retries\": 2,\n",
    "        \"retry_delay\": timedelta(minutes=3),\n",
    "    },\n",
    "    doc_md=\"\"\"### Spark/MinIO Data Pipeline\n",
    "    **Purpose**: Process smart meter data from MinIO using Spark\n",
    "    \"\"\"\n",
    ") as dag:\n",
    "    \n",
    "    processing_task = PythonOperator(\n",
    "        task_id=\"data_processing\",\n",
    "        python_callable=mock_spark_minio_etl,\n",
    "        doc=\"Transform raw JSON data to processed Parquet\"\n",
    "    )\n",
    "\n",
    "# Enhanced Visualization\n",
    "display(Markdown(\"## üîç Pipeline Visualization\"))\n",
    "dot = graphviz.Digraph(graph_attr={'rankdir': 'LR'})\n",
    "dot.node('data_processing', \n",
    "         shape='cylinder',\n",
    "         style='filled',\n",
    "         fillcolor='#FFD700',  # Gold color for Spark tasks\n",
    "         fontname='Helvetica',\n",
    "         tooltip='Spark/MinIO Processing')\n",
    "display(dot)\n",
    "\n",
    "# Interactive Testing Panel\n",
    "display(Markdown(\"## üß™ Interactive Testing\"))\n",
    "display(Markdown(\"Execute the Spark task with different parameters:\"))\n",
    "\n",
    "test_result = processing_task.execute(context={\n",
    "    \"execution_date\": datetime.now(),\n",
    "    \"params\": {\n",
    "        \"processing_time\": 1.5,\n",
    "        \"error_rate\": 0.03\n",
    "    }\n",
    "})\n",
    "\n",
    "display(Markdown(\"### üìä Execution Results\"))\n",
    "display(pd.DataFrame([test_result]).T.rename(columns={0: \"Value\"}))\n",
    "\n",
    "# Pipeline Documentation\n",
    "display(Markdown(\"## üìù Pipeline Metadata\"))\n",
    "metadata = {\n",
    "    \"DAG ID\": dag.dag_id,\n",
    "    \"Schedule\": dag.schedule_interval,\n",
    "    \"Start Date\": dag.start_date.strftime(\"%Y-%m-%d\"),\n",
    "    \"Tasks\": [t.task_id for t in dag.tasks],\n",
    "    \"Retry Policy\": f\"{dag.default_args['retries']} retries, {dag.default_args['retry_delay']} delay\"\n",
    "}\n",
    "display(pd.DataFrame(metadata.items(), columns=[\"Property\", \"Value\"]).set_index(\"Property\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d8a6df-804b-4d92-b6fc-b6841b114fca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a5d380-212a-47a9-9f16-ba7347f0dbce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42a1c1d-2d22-4951-b3fe-aabad6d692cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
